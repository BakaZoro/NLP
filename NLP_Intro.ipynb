{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Intro.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "399MlS4oy5vo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing necessary library\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import os\n",
        "import nltk.corpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bp_XoKvKzTl3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample text for performing tokenization\n",
        "text = \"I am a good boy. I love dogs very much. Dogs also love me. I really want a pet dog.\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjFHPON-0p15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# THE FIRST STEP OF NLP IS TOKENISATION\n",
        "\n",
        "#BREAKING OF SENTENCES TO BASIC UNITS"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGhHT4z1zcwZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing word_tokenize from nltk\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-EDIKyGzmKe",
        "colab_type": "code",
        "outputId": "3a952c53-1a0a-458e-e6f8-8e221793acb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# #In case the punkt package is missing \n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6TWtkVrzfRw",
        "colab_type": "code",
        "outputId": "b6c68474-dee7-4cfd-cb7c-23789436272a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# Passing the string text into word tokenize for breaking the sentences\n",
        "token = word_tokenize(text)\n",
        "token"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'am',\n",
              " 'a',\n",
              " 'good',\n",
              " 'boy',\n",
              " '.',\n",
              " 'I',\n",
              " 'love',\n",
              " 'dogs',\n",
              " 'very',\n",
              " 'much',\n",
              " '.',\n",
              " 'Dogs',\n",
              " 'also',\n",
              " 'love',\n",
              " 'me',\n",
              " '.',\n",
              " 'I',\n",
              " 'really',\n",
              " 'want',\n",
              " 'a',\n",
              " 'pet',\n",
              " 'dog',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6u9I6S9z4Hc",
        "colab_type": "code",
        "outputId": "e9f8b94d-e4f6-4cc3-f8c8-26d047b1a096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "# finding the frequency distinct in the tokens\n",
        "# Importing FreqDist library from nltk and passing token into FreqDist\n",
        "from nltk.probability import FreqDist\n",
        "fdist = FreqDist(token)\n",
        "fdist"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FreqDist({'.': 4,\n",
              "          'Dogs': 1,\n",
              "          'I': 3,\n",
              "          'a': 2,\n",
              "          'also': 1,\n",
              "          'am': 1,\n",
              "          'boy': 1,\n",
              "          'dog': 1,\n",
              "          'dogs': 1,\n",
              "          'good': 1,\n",
              "          'love': 2,\n",
              "          'me': 1,\n",
              "          'much': 1,\n",
              "          'pet': 1,\n",
              "          'really': 1,\n",
              "          'very': 1,\n",
              "          'want': 1})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOVPRWeP0Ysr",
        "colab_type": "code",
        "outputId": "00b48518-383c-453c-9289-a90e3e6218d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "# To find the frequency of top 10 words\n",
        "fdist1 = fdist.most_common(10)\n",
        "fdist1"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('.', 4),\n",
              " ('I', 3),\n",
              " ('a', 2),\n",
              " ('love', 2),\n",
              " ('am', 1),\n",
              " ('good', 1),\n",
              " ('boy', 1),\n",
              " ('dogs', 1),\n",
              " ('very', 1),\n",
              " ('much', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZJr9yik0lTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SECOND STEP BEING STEMMING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-91BUjB3Q3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# STEMMING BREAKS WORDS TO THEIR ROOT FORM. LIKE DOGS TO DOG.\n",
        "\n",
        "# THERE ARE TWO FORMS OF STEMMING. \n",
        "#1. PORTER STEMMING\n",
        "#2. LANCESTER STEMMING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9q5XaDdbDlH6",
        "colab_type": "code",
        "outputId": "b01d361e-c7de-4c87-c661-37d8f493f11b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Importing Porterstemmer from nltk library\n",
        "from nltk.stem import PorterStemmer\n",
        "pst = PorterStemmer()\n",
        "pst.stem(\"caring\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'care'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Hm7EwubHeyR",
        "colab_type": "code",
        "outputId": "fc86b13e-8f78-4940-b5e3-7fd6f0c0d877",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Testint the Porter Stemmer\n",
        "stm = [\"going\", \"go\",\"gone\"]\n",
        "for word in stm :\n",
        "   print(word+ \":\" +pst.stem(word))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "going:go\n",
            "go:go\n",
            "gone:gone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQVJ5C3lEHSi",
        "colab_type": "code",
        "outputId": "99ddf93c-2d9c-4f77-96e5-66120bb14cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Checking for the list of words\n",
        "stm = [\"dogs\", \"Dogs\"]\n",
        "for word in stm :\n",
        "   print(word+ \":\" +pst.stem(word))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dogs:dog\n",
            "Dogs:dog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIzZU39HGqSm",
        "colab_type": "code",
        "outputId": "2cd53ed3-f7c5-43f3-ae4b-3fc5285e6d13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Importing LancasterStemmer from nltk\n",
        "from nltk.stem import LancasterStemmer\n",
        "lst = LancasterStemmer()\n",
        "stm1 = [\"giving\", \"given\", \"given\", \"gave\"]\n",
        "for word in stm1 :\n",
        " print(word+ \":\" +lst.stem(word))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "giving:giv\n",
            "given:giv\n",
            "given:giv\n",
            "gave:gav\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4tGC136IDV_",
        "colab_type": "code",
        "outputId": "fa8d6887-a2eb-4497-c2a0-9610117718fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "stm1 = [\"cares\", \"care\",\"caring\"]\n",
        "for word in stm1 :\n",
        " print(word+ \":\" +lst.stem(word))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cares:car\n",
            "care:car\n",
            "caring:car\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNirqjf5IM58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#THE THIRD STEP IS LEMMATIZATION  \n",
        "# LEMMATIZATION ALSO MAPS A WORD TO ITS ROOT FORM,SOMEHOW SIMILIAR TO STEMMING"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwBlWoSgZ6IA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer=WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_mAG6C6L132",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5bf7373b-fa31-4897-d94e-0c9a82ea11d9"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swUCKPA4LnV9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "59b881c5-783d-4428-e4d4-bab60e309cec"
      },
      "source": [
        "print(\"cares :\", lemmatizer.lemmatize(\"cares\")) \n",
        "print(\"corpora :\", lemmatizer.lemmatize(\"corpora\"))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cares : care\n",
            "corpora : corpus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMYVlg6ZMAGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importing stopwors from nltk library\n",
        "from nltk.corpus import stopwords\n",
        "a = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U99SgVB2OYRh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f293ac7d-eb69-4013-bc70-17d8add4ba98"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItKzddNeOeO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text=text.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IgtkHWQiOupv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4ef4fba0-b6ac-4cb4-f696-250d8983d607"
      },
      "source": [
        "text"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i am a good boy. i love dogs very much. dogs also love me. i really want a pet dog.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ct-KyVsOw1j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token=word_tokenize(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2zR7WC9O3C-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "55d449b5-1866-497d-bc6c-4a3a1ad8776b"
      },
      "source": [
        "token"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'am',\n",
              " 'a',\n",
              " 'good',\n",
              " 'boy',\n",
              " '.',\n",
              " 'i',\n",
              " 'love',\n",
              " 'dogs',\n",
              " 'very',\n",
              " 'much',\n",
              " '.',\n",
              " 'dogs',\n",
              " 'also',\n",
              " 'love',\n",
              " 'me',\n",
              " '.',\n",
              " 'i',\n",
              " 'really',\n",
              " 'want',\n",
              " 'a',\n",
              " 'pet',\n",
              " 'dog',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgCWxdOPO5He",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "583227f0-aae7-4c7e-af75-6784e85ec215"
      },
      "source": [
        "stopwords=[w for w in token if w not in a]\n",
        "print(stopwords)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['good', 'boy', '.', 'love', 'dogs', 'much', '.', 'dogs', 'also', 'love', '.', 'really', 'want', 'pet', 'dog', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lf5sHsqFPf6y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2a58700d-1afd-4d34-d942-e6d4fa596210"
      },
      "source": [
        "#TAGGING SENTENCES WITH THE APPROPRIATE PARTS OF SPEECH (POS TAGGING)\n",
        "print(nltk.pos_tag(token))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('i', 'NN'), ('am', 'VBP'), ('a', 'DT'), ('good', 'JJ'), ('boy', 'NN'), ('.', '.'), ('i', 'JJ'), ('love', 'VBP'), ('dogs', 'NNS'), ('very', 'RB'), ('much', 'RB'), ('.', '.'), ('dogs', 'NNS'), ('also', 'RB'), ('love', 'VBP'), ('me', 'PRP'), ('.', '.'), ('i', 'VB'), ('really', 'RB'), ('want', 'VB'), ('a', 'DT'), ('pet', 'JJ'), ('dog', 'NN'), ('.', '.')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI_QhdVVT7gj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "e7bf04b9-7098-45c1-bfd0-1a3f1ddd38ca"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJPUYxj2VS7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NAMED ENTITY RECOGNITION"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uV6lgXyEVU9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text1='My name is Amartya Dutta and I am doing a challenge at IEEE , California.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBHir6pgW2nv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f1541102-a1c1-43f5-95d6-44af5e8ae2ab"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLnQPF94W9EU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "20a4e4bf-9bff-4eed-e09b-1ec278823233"
      },
      "source": [
        "nltk.download('words')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yddxasVWcrZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1596645d-dac1-4dc3-ac79-ec20f250f340"
      },
      "source": [
        "#importing chunk library from nltk\n",
        "from nltk import ne_chunk\n",
        "# tokenize and POS Tagging before doing chunk\n",
        "token1 = word_tokenize(text1)\n",
        "tags = nltk.pos_tag(token1)\n",
        "chunk = ne_chunk(tags)\n",
        "print(chunk)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(S\n",
            "  My/PRP$\n",
            "  name/NN\n",
            "  is/VBZ\n",
            "  (PERSON Amartya/NNP Dutta/NNP)\n",
            "  and/CC\n",
            "  I/PRP\n",
            "  am/VBP\n",
            "  doing/VBG\n",
            "  a/DT\n",
            "  challenge/NN\n",
            "  at/IN\n",
            "  (ORGANIZATION IEEE/NNP)\n",
            "  ,/,\n",
            "  (GPE California/NNP)\n",
            "  ./.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Obc7snoTYLqR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}